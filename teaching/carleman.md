@def title = "Corrections suppl√©mentaires (PR7)"
@def hascode = true

\tableofcontents

## TD8 Exercice 11

J'ai re√ßu plusieurs mails me demandant une correction de l'exercice 11 du TD8. La voici (v√©rifiez bien les d√©tails, ils y a peut-√™tre des coquilles). 

Bon courage pour les r√©visions ! üéÖüéÖüéÖüéÖ

a) L'int√©grale fait 1 donc c'est une densit√©. Comme la densit√© est une fonction sym√©trique, l'esp√©rance est nulle :¬†$\mathbb{E}[X]=0$. Encore par sym√©trie, on a $\mathbb{E}[X^2] = 2\int_1^\infty x^2 / x^3 dx = +\infty$. Le TCL¬†ne s'applique pas car $X$ n'est donc pas $L^2$. 

b) Comme $X$ a une loi sym√©trique on a $\varphi(-t) = \varphi(t)$. De plus, on a toujours $\varphi(-t) = \overline{\varphi(t)}$. On en d√©duit que $\varphi(t) = \overline{\varphi(t)}$, c'est-√†-dire que $\varphi$ est en fait une fonction √† valeurs r√©elles, et donc $\varphi(t) = \mathrm{Re}\mathbb{E}[e^{itX}] = \mathbb{E}[\cos(tX)]$. Le cosinus et la densit√© de $X$ √©tant des fonctions sym√©triques, on peut √©crire 
$$ \varphi(t) = 2\int_1^\infty \frac{\cos(tx)}{x^3}dx.$$ 
Le changement de variables $y = tx$ donne  
$$ \varphi(t) = 2 t^2 \int_t^\infty \frac{\cos(y)}{y^3}dy $$
On √©crit artificiellement $\cos(y) = 1 - (1 - \cos(y))$. Comme $\int_t^\infty 1/y^3 dy = [-2/y^2]_t^\infty = 2t^2$, on en d√©duit que 
$$\varphi(t) = \frac{2t^2}{2t^2} - 2t^2\int_t^\infty \frac{1 - \cos(y)}{y^3}dy $$
ce qui est bien l'identit√© demand√©e. 

c) Il s'agit essentiellement de montrer que la fonction $g(t)$ d√©finie par $g(t) = \int_t^\infty (1 - \cos(y))y^{-3}dy $ v√©rifie $g(t)\sim -\ln(t)/2$ lorsque $t\to 0^+$ (ou plus pr√©cis√©ment $g(t) = -\ln(t)/2 + o(\ln(t)))$. 

**Id√©e** :¬†On coupe l'int√©grale en $a$ (√† choisir plus tard), $g(t) = \int_t^a‚Ä¶ + \int_a^\infty‚Ä¶$; le second terme est une constante donc on l'oublie. On va montrer que le premier terme est √©quivalent √† $\ln(1/t)/2$.  Pr√®s de 0 on a $\cos(x) \sim 1 - x^2/2 + o(x^2)$, donc en z√©ro la fonction dans l'int√©grale est $\sim 1/2x$ et l'int√©grale devrait √™tre comparable √† l'int√©grale de $ \int_t^a    1/2ydy = (\ln(a)-\ln(t))/2 \sim ln(1/t)/2$.

**Je vous laisse essayer par vous-m√™me de rendre rigoureuse cette id√©e (indice : bien choisir $a$ et bien quantifier le petit o dans l'√©quivalent du cos).** Envoyez moi un mail si vous avez des questions. 




d) Comme les $X_i$ sont iid, $\varphi_{Z_n}(t) = \varphi(t/\sqrt{n\ln(n)})^n$. Lorsque $n\to \infty$, la question pr√©c√©dente montre que ceci est √©quivalent √† $$\exp\left(n\ln\left(1 - \frac{t^2}{n\ln(n)}\ln\left(\frac{t}{\sqrt{n\ln(n)}}\right) + o(t^2 / n\ln(n))\right)\right)$$
Il faut calculer cette limite. L'√©quivalent usuel du logarithme en z√©ro est suffisant:¬†on voit que le terme dans l'exponentielle est √©quivalent √† 
\begin{align}- \frac{nt^2}{n\ln(n)}\ln(t) - \frac{nt^2(\ln(n) + \ln\ln(n))}{2n\ln(n)} + o(t^2/\ln(n))& = \frac{t\ln(t)}{\ln(n)} - \frac{t^2}{2} - \frac{t^2\ln\ln(n)}{2\ln(n)} + o(1) \\ &= o(1) - t^2/2 + o(1) + o(1) \\ &= -t^2/2 + o(1)\end{align}
ce qui veut pr√©cis√©ment dire que $\varphi_{Z_n}(t)\to e^{-t^2/2}$, et donc par le th√©or√®me de Paul L√©vy que $Z_n$ converge en loi vers $\mathscr{N}(0,1)$. 

e) La fonction $x \mapsto e^{-\theta x^2}$ est une fonction continue born√©e. Par cons√©quent, la convergence en loi de la question pr√©c√©dente entra√Æne que $\mathbb{E}[e^{-\theta Z_n^2}] \to \mathbb{E}[e^{-\theta N^2}]$ o√π $N$ est une gaussienne standard. Le carr√© d'une gaussienne standard suit une loi du chi-deux avec param√®tre 1 (qui est aussi une loi $\Gamma(1/2, 1/2)$). On a d√©j√† vu la transform√©e de Laplace de ces lois:¬†
$$ \mathbb{E}[e^{-\theta N^2}] = \left(\frac{1}{1 + 2\theta}\right)^{1/2}$$

## Th√©or√®me de Carleman :¬†TD7 exercice 12

L'objectif est de montrer que si une suite de variables $X_n$ est uniform√©ment sous-gaussienne, c'est-√†-dire s'il existe $C,c$ telles que pour tout $x$, 
$$\mathbb{P}(|X_n|>x)\leq Ce^{-cx^2}$$
alors la convergence en loi des $X_n$ et la convergence des moments sont √©quivalentes. 

Ce th√©or√®me (sous une forme plus forte) est d√ª √† [Torsten Carleman](https://en.wikipedia.org/wiki/Torsten_Carleman), math√©maticien su√©dois peu fr√©quentable. 

### Correction de l'exercice 12 du TD 7:¬†le th√©or√®me de Carleman
\newcommand{\P}{\mathbb{P}}
\newcommand{\E}{\mathbb{E}}

On rappelle que si $X$ est positive alors 
\begin{equation}\label{1}\mathbb{E}X = \int_0^\infty \P(X>x)dx. \end{equation}

### a)

 En utilisant \eqref{1} on voit que 
\begin{align}\E|X_n|^k &= \int_0^\infty \P(|X_n|^k>x)dx \\ 
&= \int_0^\infty \P(|X_n|>x^{1/k})dx \\ 
&\leqslant \int_0^\infty Ce^{-cx^{2/k}}dx = A < \infty \end{align}
ce qui montre que les $X_n$ ont bien des moments √† tous les ordres. 

Par ailleurs si l'on pose $f_n(x) = \P(|X_n|>x^{1/k}), f(x) = \P(|X|>x^{1/k})$ et $F_n(x) = \P(X_n \leqslant x), F(x) = \P(X\leqslant x)$ on voit que 

- sur $\mathbb{R}_+$ ces fonctions sont domin√©es par la fonction $Ce^{-x^{2/k}}$ qui est int√©grable; 

- $f_n(x) = \P(X_n < -x^{1/k}) + \P(X_n > x^{1/k}) = \lim_{t\stackrel{<}{\to} -x^{1/k}}F_n(t) + 1 - F_n(x^{1/k})$. Or, comme $X_n$ converge en loi vers $X$, $F_n$ converge vers $F$ en tout point de continuit√© de $F$. Or, les points de discontinuit√© d'une fonction croissante sont au plus d√©nombrables, donc de mesure de Lebesgue nulle, donc $F_n \to F$ presque partout. On en d√©duit que $f_n \to f$ presque partout. 

Par le th√©or√®me de convergence domin√©e on a donc $\mathbb{E}|X_n|^k = \int_0^\infty f_n \to \int_0^\infty f = \mathbb{E}|X|^k$. De plus, comme $\E|X_n|^k \leqslant A$ pour tout $A$, on en d√©duit imm√©diatement que $\E|X|^k \leqslant A$ donc en plus, tous les moments de $X$ sont finis. 

Cela montre la convergence de tous les moments absolus, donc aussi de tous les moments d'ordre pair. Pour la convergence des moments impairs, on d√©compose en partie positive/n√©gitave : $X_n = A_n - B_n$. En fait, $A_n = \sigma(X_n)$ avec $\sigma(x) = \max\{x,0\}$ et $\sigma$ est une fonction continue;¬†or, si $X_n$ converge en loi, toutes les fonctions continues[^1] de $X_n$ aussi, donc $\sigma(X_n)$ converge en loi vers $\sigma(X)$ qui est la partie positive de $X$, et de m√™me $B_n = X_n - \sigma(X_n)$ converge en loi vers la partie n√©gative de $X$, not√©e $B$.  

Comme la partie positive et n√©gative de $X_n$ sont √©galement sous-gaussiennes avec les m√™mes constantes, on applique ce qui a √©t√© vu plus haut;¬†on en d√©duit que $\E[A^k_n] \to \mathbb{E}A^k$ et $\E B_n^k \to \E B^k$. Or, comme $k$ est impair, 
$$ \E X_n^k = \E [A_n^k - B_n^k]= \E[A_n^k] - \E[B_n^k] \to \E[A^k] - \E[B^k] = \E[X^k].  $$ 


### b)

### i) 

On a vu que comme les $X_n$ sont sous-gaussiennes, 

$$\E[|X_n|^{k+1}] \leqslant \int_0^\infty Ce^{-cx^{2/(k+1)}}dx. $$
En posant $y = cx^{2/(k+1)}$ cette borne devient 
\begin{equation}\label{2} Cc^{-(k+1)/2}\frac{k+1}{2} \int_0^\infty e^{-y}y^{(k-1)/2}dy = \frac{C(k+1)}{c^{k/2}\sqrt{c}2}\Gamma((k+1)/2) .\end{equation}
De plus la fonction $\Gamma$ v√©rifie la borne suivante:¬†si $m\leqslant x < m+1$ avec $m$ entier alors par croissance $ \Gamma(x)\leq \Gamma(m+1) = m!\leq m^m\leq x^x$. Par cons√©quent \eqref{2} est plus petit que 
$$ \frac{C (k+1)}{c^{k/2}2\sqrt{c}}((k+1)/2)^{(k+1)/2}$$
et comme $(k+1)/2 \leq k$, tout ceci est plus petit que 
$$\frac{C}{2\sqrt{c}}\frac{k^{k/2 + 3/2}}{c^{k/2}}=  \frac{C}{2\sqrt{c}}(k/c)^{k/2} k^{3/2}$$
Par croissance compar√©e $k^{3/2} \leq (k/c)^{k/2}$ d√®s que $k$ est suffisamment grand, donc quitte √† ajuster les constantes on voit qu'il existe $a$ tel que tout ceci est plus petit que $(ak)^{k/2}$ comme demand√©. 

### ii) 

Par convergence domin√©e (pourquoi ?) on peut √©crire que 
\begin{equation}\label{phi}\varphi_n(t) = \sum_{j=0}^\infty \frac{i^jt^j}{j!}\mathbb{E}X_n^j.\end{equation}
Par simplicit√© on ne regardera que les $t$ positifs, le cas n√©gatif marche de la m√™me mani√®re. 

On coupe la somme √† un $k$ entier et on borne brutalement le reste, qu'on notera $r=r(n,k,t)$:¬†
$$ |r(n,k,t)| \leq \sum_{j>k} \frac{t^{j+1}}{(j+1)!}(aj)^{j/2}.$$
On a $(j+1)!>j!$ et l'√©quivalent de Stirling dit que $j!>c j^j \sqrt{j}e^{-j}$. La constante ne jouant aucun r√¥le, on l'oublie (en fait cette in√©galit√© est vraie pour tout $j$ pour $c=1$). Ainsi, le reste devient born√© par 
\begin{align}
|r|&\leq \sum_{j>k}\frac{t[t \sqrt{a} \sqrt{j}]^j}{j^j \sqrt{j}e^{-j}}\\
&\leq t\sum_{j>k} \left(\frac{tae}{\sqrt{aj}}\right)^j \frac{1}{\sqrt{j}} \\
&\leq t\sum_{j>k} \rho_j^j 
\end{align}
o√π, √† la derni√®re ligne, j'ai utilis√© $1/\sqrt{j}\leq 1$ et j'ai pos√© $\rho_j = tae / \sqrt{ja}$. D√®s que $k$ est plus grand que $4t^2 a e$ on voit que $\rho_j < \rho_k \times (1/2)^{j-k}$.  Par cons√©quent la borne ci-dessus devient plus petite que $t\rho_k^k (1 - 1/2)^{-1} = 2t\rho_k^k$ (s√©rie g√©om√©trique de raison 1/2). Or, 
$$ 2t\rho_k^k = 2t\left(\frac{tae}{\sqrt{ak}}\right)^k = t^{k+1}(ak)^{-k/2} (ae)^k = t^{k+1}(bk)^{-k/2}$$
o√π $b$ est une nouvelle constante, $b=1/ae^2$ (si on veut exactement l'√©nonc√© de l'exercice, on met $(ae)^k$ dans la constante du $O(...)$. 

### iii) 

On fixe $t$ et $k$, on a 
$$ \varphi_n(t) = \sum_{j=0}^k \frac{i^jt^j}{j!}\mathbb{E}X_n^j + r(n,k,t). $$
 
Comme les $\E X_n^j$ convergent vers $\E X^j$,on voit que $\E X^{j+1}\leq (aj)^{j/2}$. L'analyse faite √† la question ii) est donc encore valable pour $X$, en particulier 
$$ \varphi(t) = \sum_{j=0}^k \frac{i^jt^j}{j!}\E X^j + r'(k,t) $$
o√π $|r'(k,t)| \leq t^{k+1} (bk)^{-k/2}$. 

On en d√©duit que 
$$ |\varphi_n(t) - \varphi(t)| \leq \sum^k_0 \frac{t^j}{j!}|\E X_n^j - \E X^j| + |r| + |r'|.$$

Pour conclure, il faut faire attention √† l'ordre dans lequel on prend les limites. On fixe d'abord $t$ et on choisit $\epsilon$. Comme $r$ et $r'$ tendent vers 0 quand $k\to \infty$ on choisit un $k$ tr√®s tr√®s grand pour que $|r| + |r'| \leq \epsilon/2$. Ensuite  on fait  $n\to \infty$ et le premier terme tend vers 0, donc il est plus petit que $\epsilon/2$. 

In fine, on obtient bien que $|\varphi_n(t) -  \varphi(t)| \to 0$, donc il y a convergence en loi.  


[^1] pas forc√©ment born√©es !